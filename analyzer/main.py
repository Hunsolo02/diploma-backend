# train_landmarks.py
import os
import torch
import torch.nn as nn
from torch.utils.data import DataLoader, random_split
import torch.optim as optim
from tqdm import tqdm

from datasetFace import FaceLandmarkDataset
from model import LandmarkModel  # –ª—É—á—à–µ –¥–µ—Ä–∂–∞—Ç—å –º–æ–¥–µ–ª—å –≤ model.py


# ====== –ü–∞—Ä–∞–º–µ—Ç—Ä—ã ======
json_path = "/home/ermakov/webproj/trainModel2/huggingface_landmarks.json"
save_path = "/home/ermakov/webproj/trainModel2/landmark_model.pth"

IMG_SIZE = 128
BATCH_SIZE = 64
EPOCHS = 60
LR = 1e-4
WEIGHT_DECAY = 1e-4
SEED = 42


def set_seed(seed: int):
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)


def main():
    set_seed(SEED)

    device = "cuda" if torch.cuda.is_available() else "cpu"

    print("‚úÖ –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞ (HF + landmarks [0..1])...")
    # –í–∞—Ä–∏–∞–Ω—Ç 1: –¥–∞—Ç–∞—Å–µ—Ç —á–∏—Ç–∞–µ—Ç –∫–∞—Ä—Ç–∏–Ω–∫–∏ –∏–∑ HF –ø–æ hf_index, image_dir –Ω–µ –Ω—É–∂–µ–Ω
    dataset = FaceLandmarkDataset(json_path, img_size=IMG_SIZE)

    # –õ—É—á—à–µ –±—Ä–∞—Ç—å num_points –∏–∑ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –¥–∞—Ç–∞—Å–µ—Ç–∞, –∞ –Ω–µ —á–µ—Ä–µ–∑ dataset[0]
    num_points = getattr(dataset, "num_points", None)
    if num_points is None:
        num_points = len(dataset[0][1]) // 2
    print("üî¢ num_points:", num_points, "| output dims:", num_points * 2)

    # split train/val (80/20)
    train_size = int(0.8 * len(dataset))
    val_size = len(dataset) - train_size
    train_dataset, val_dataset = random_split(dataset, [train_size, val_size])

    print(f"üìä –†–∞–∑–º–µ—Ä—ã: train={len(train_dataset)}, val={len(val_dataset)}")

    train_loader = DataLoader(
        train_dataset,
        batch_size=BATCH_SIZE,
        shuffle=True,
        num_workers=4,
        pin_memory=True
    )
    val_loader = DataLoader(
        val_dataset,
        batch_size=BATCH_SIZE,
        shuffle=False,
        num_workers=4,
        pin_memory=True
    )

    # ====== –ú–æ–¥–µ–ª—å ======
    model = LandmarkModel(num_points).to(device)

    # ‚úÖ –†–∞–∑ landmarks –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ [0..1], –≤—ã—Ö–æ–¥ –º–æ–¥–µ–ª–∏ —Ç–æ–∂–µ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å [0..1]
    # –°–∞–º—ã–π –ø—Ä–æ—Å—Ç–æ–π —Å–ø–æ—Å–æ–±: —Å–∏–≥–º–æ–∏–¥–∞ –Ω–∞ –≤—ã—Ö–æ–¥
    # –ï—Å–ª–∏ –≤ LandmarkModel —É–∂–µ –µ—Å—Ç—å Sigmoid ‚Äî —ç—Ç—É —Å—Ç—Ä–æ–∫—É –Ω–µ –Ω–∞–¥–æ.
    if not hasattr(model, "has_sigmoid_head"):
        # –ù–µ —Ç—Ä–æ–≥–∞–µ–º –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É –≤–Ω—É—Ç—Ä–∏, –ø—Ä–æ—Å—Ç–æ –æ–±–æ—Ä–∞—á–∏–≤–∞–µ–º –≤—ã—Ö–æ–¥
        model = nn.Sequential(model, nn.Sigmoid()).to(device)

    # Loss: SmoothL1 —É—Å—Ç–æ–π—á–∏–≤–µ–µ, —á–µ–º MSE –¥–ª—è –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç
    criterion = nn.SmoothL1Loss(beta=0.01)

    optimizer = optim.AdamW(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)

    # Scheduler (–Ω–µ –æ–±—è–∑–∞—Ç–µ–ª–µ–Ω, –Ω–æ –ø–æ–º–æ–≥–∞–µ—Ç)
    scheduler = optim.lr_scheduler.ReduceLROnPlateau(
        optimizer, mode="min", factor=0.5, patience=4
    )

    best_val = float("inf")

    print("üöÄ –ù–∞—á–∏–Ω–∞–µ—Ç—Å—è –æ–±—É—á–µ–Ω–∏–µ...\n")
    for epoch in range(EPOCHS):
        model.train()
        total_loss = 0.0

        pbar = tqdm(train_loader, desc=f"üèãÔ∏è Train {epoch+1}/{EPOCHS}", leave=False)
        for images, landmarks in pbar:
            images = images.to(device, non_blocking=True)
            landmarks = landmarks.to(device, non_blocking=True)

            preds = model(images)
            loss = criterion(preds, landmarks)

            optimizer.zero_grad(set_to_none=True)
            loss.backward()
            nn.utils.clip_grad_norm_(model.parameters(), 1.0)
            optimizer.step()

            total_loss += float(loss.item())
            pbar.set_postfix(loss=float(loss.item()), lr=optimizer.param_groups[0]["lr"])

        avg_train_loss = total_loss / max(1, len(train_loader))

        # ====== –í–∞–ª–∏–¥–∞—Ü–∏—è ======
        model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for images, landmarks in val_loader:
                images = images.to(device, non_blocking=True)
                landmarks = landmarks.to(device, non_blocking=True)

                preds = model(images)
                loss = criterion(preds, landmarks)
                val_loss += float(loss.item())

        avg_val_loss = val_loss / max(1, len(val_loader))
        scheduler.step(avg_val_loss)

        print(f"üìâ Epoch {epoch+1}/{EPOCHS}: Train={avg_train_loss:.6f} | Val={avg_val_loss:.6f}")

        # ====== Save best ======
        if avg_val_loss < best_val:
            best_val = avg_val_loss
            os.makedirs(os.path.dirname(save_path), exist_ok=True)
            # –µ—Å–ª–∏ –º–æ–¥–µ–ª—å –æ–±—ë—Ä–Ω—É—Ç–∞ Sequential(model, Sigmoid), —Å–æ—Ö—Ä–∞–Ω–∏–º "—Å—ã—Ä—É—é" —á–∞—Å—Ç—å —Ç–æ–∂–µ:
            state_to_save = model.state_dict()
            torch.save(state_to_save, save_path)
            print(f"‚úÖ Best model saved: {save_path} (val={best_val:.6f})")

    print("üèÅ Training finished.")
    print("‚úÖ Final best val:", best_val)


if __name__ == "__main__":
    main()
